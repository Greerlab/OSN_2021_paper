{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "import pickle \n",
    "from collections import Counter\n",
    "# Initialize linear regression\n",
    "model = LinearRegression()\n",
    "# Set random seed \n",
    "random_state = 12\n",
    "# Set minimum number of cells \n",
    "min_cells = 7\n",
    "# Read Slide-seq transformed coorindates\n",
    "print(\"Loading coordinates\")\n",
    "df = pd.read_csv(\"data/transformed_coords_1to2.txt\",\n",
    "                 sep = \"\\t\", header=None, names=[\"OR\", \"X\", \"Y\", \"EXP\"])\n",
    "# Average coordinates shared between the two experiments\n",
    "df = df.groupby(\"OR\").agg({\"X\" : \"mean\", \"Y\" : \"mean\", \"EXP\" : \"sum\"})\n",
    "# This is just a quick and dirty way to remove the OR that falls of the slide without knowing its ID\n",
    "df = df[df[\"Y\"] < 0]\n",
    "ORs = sorted(list(df.index))\n",
    "print(\"{} ORs with Slide-seq coordinates\".format(len(ORs)))\n",
    "# Convert coordinates to a dictionary keyed on OR\n",
    "coords = df[[\"X\", \"Y\"]].to_dict(\"index\")\n",
    "# Fit scaler so it stores the min and max of the x and y coordinates\n",
    "scaler_y = MinMaxScaler().fit(df[[\"X\", \"Y\"]].values)\n",
    "# Read in PCs\n",
    "df = pd.read_csv(\"data/All_OSN_PC.txt\", sep = \"\\t\", index_col=0)\n",
    "n_col = len(df.columns)\n",
    "df.rename(columns={\"OR_identity\": \"OR\"}, inplace=True)\n",
    "print(df.head())\n",
    "# Only retain PCs for ORs with slide-seq coordinates\n",
    "df = df[df[\"OR\"].isin(ORs)]\n",
    "ORs_to_exclude = [x for x in ORs if len(df[df[\"OR\"] == x]) < min_cells]\n",
    "print(ORs_to_exclude)\n",
    "df = df[~df[\"OR\"].isin(ORs_to_exclude)]\n",
    "print(\"{} ORs with Slide-seq coordinates but no gene expression\".format(len(ORs_to_exclude)))\n",
    "ORs = list(df.OR.unique())\n",
    "print(\"{} ORs remaining\".format(len(ORs)))\n",
    "# Z-score normalize PCs\n",
    "scaler_x = StandardScaler().fit(df.values[:,0:(n_col - 1)])\n",
    "# Generating train and eval set \n",
    "X_train = df.values[:,0:(n_col - 1)]\n",
    "X_train = scaler_x.transform(X_train)\n",
    "train_ors = np.array(df.iloc[:,(n_col - 1)])\n",
    "# Use KNN to oversample less represented cells to remove any potential bias\n",
    "# created by ORs with large numbers of cells\n",
    "counter = Counter(train_ors)\n",
    "oversample = SMOTE(random_state=random_state)\n",
    "X_train, train_ors = oversample.fit_resample(X_train, train_ors)\n",
    "counter = Counter(train_ors)\n",
    "max_cells = np.max(list(counter.values()))\n",
    "# Generate coordinate vectors from coordinate dictionary and ORs\n",
    "y_train = []\n",
    "for i in range(train_ors.shape[0]):\n",
    "    y_train.append([coords[train_ors[i]][\"X\"], coords[train_ors[i]][\"Y\"]])\n",
    "y_train = np.array(y_train)\n",
    "# Scale coordinates\n",
    "y_train = scaler_y.transform(y_train)\n",
    "# Fit linear regression\n",
    "model.fit(X_train, y_train)\n",
    "# Pickle model\n",
    "model_file = \"data/model.pkl\"\n",
    "pickle.dump(model, open(model_file, 'wb'))\n",
    "np.savetxt(\"data/coefficients.txt\", np.transpose(model.coef_))\n",
    "f_x, p_x = f_regression(X_train, y_train[:,0])\n",
    "f_y, p_y = f_regression(X_train, y_train[:,1])\n",
    "with open(\"data/coefficient_p_values.txt\", \"w\") as f:\n",
    "    for i in range(p_x.shape[0]):\n",
    "        print(\"x\", i+1, \"{:e}\".format(p_x[i]), file = f, sep=\"\\t\")\n",
    "    for i in range(p_y.shape[0]):\n",
    "        print(\"y\", i+1, \"{:e}\".format(p_y[i]), file = f, sep=\"\\t\")\n",
    "# Run lr on bootstrap samples to get prediction intervals\n",
    "STDS_X = []\n",
    "STDS_Y = []\n",
    "print(len(ORs))\n",
    "for i in range(100):\n",
    "    bootstrap_ORs = np.random.choice(ORs, len(ORs))\n",
    "    pc_arrays = []\n",
    "    coord_arrays = []\n",
    "    for x in bootstrap_ORs:\n",
    "        indices = [j for j in range(len(train_ors)) if train_ors[j] == x]\n",
    "        pc_arrays.append(X_train[indices,:])\n",
    "        coord_arrays.append(y_train[indices,:])\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.vstack(pc_arrays), np.vstack(coord_arrays))\n",
    "    preds = model.predict(np.vstack(pc_arrays))\n",
    "    x_preds = []\n",
    "    y_preds = []\n",
    "    x_true = []\n",
    "    y_true = []\n",
    "    coord_arrays = scaler_y.inverse_transform(np.vstack(coord_arrays))\n",
    "    for j, x in enumerate(bootstrap_ORs):\n",
    "        x_preds.append(np.mean(preds[j*max_cells:(j*max_cells + max_cells),0]))\n",
    "        y_preds.append(np.mean(preds[j*max_cells:(j*max_cells + max_cells),1]))\n",
    "        x_true.append(np.mean(coord_arrays[j*max_cells:(j*max_cells + max_cells),0]))\n",
    "        y_true.append(np.mean(coord_arrays[j*max_cells:(j*max_cells + max_cells),1]))\n",
    "    x_preds = np.array(x_preds)\n",
    "    y_preds = np.array(y_preds)\n",
    "    mean_preds = np.transpose(np.vstack((x_preds, y_preds)))\n",
    "    mean_preds = scaler_y.inverse_transform(mean_preds)\n",
    "    x_true = np.array(x_true)\n",
    "    y_true = np.array(y_true)\n",
    "    stdev_x = np.sqrt(1/(len(ORs)-2) * np.sum((x_true - mean_preds[:,0])**2))\n",
    "    stdev_y = np.sqrt(1/(len(ORs)-2) * np.sum((y_true - mean_preds[:,1])**2))\n",
    "    STDS_X.append(stdev_x)\n",
    "    STDS_Y.append(stdev_y)\n",
    "print(np.mean(STDS_X), np.mean(STDS_Y))\n",
    "# Make predictions on all other ORs\n",
    "df = pd.read_csv(\"data/All_OSN_PC.txt\", sep = \"\\t\", index_col=0)\n",
    "df.rename(columns={\"OR_identity\": \"OR\"}, inplace=True)\n",
    "n_col = len(df.columns)\n",
    "model_file = \"model.pkl\"\n",
    "model = pickle.load(open(model_file, 'rb'))\n",
    "all_ORs = list(df.OR.unique())\n",
    "ORs_of_interest = [x for x in all_ORs if len(df[df[\"OR\"] == x]) >= min_cells]\n",
    "print(len(ORs_of_interest))\n",
    "with open(\"data/map_654.txt\", \"w\") as f:\n",
    "    for OR in ORs_of_interest:\n",
    "        X = df[df[\"OR\"] == OR].values[:,0:(n_col - 1)]\n",
    "        n = X.shape[0]\n",
    "        X = scaler_x.transform(X)\n",
    "        pred = scaler_y.inverse_transform(model.predict(X))\n",
    "        pred = np.mean(pred, axis=0)\n",
    "        x_pred, y_pred = pred\n",
    "        print(OR,n,\"predicted\",x_pred,y_pred, file=f, sep=\"\\t\")\n",
    "        if OR in ORs:\n",
    "            print(OR, n, \"slide-seq\", coords[OR][\"X\"], coords[OR][\"Y\"], file=f, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
